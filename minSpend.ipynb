{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plausability of Lottery Luck\n",
    "\n",
    "#### [Dylan D. Daniels](http://statistics.berkeley.edu/people/dylan-david-daniels) and [Philip B. Stark](www.stat.berkeley.edu/~stark), Department of Statistics, University of California, Berkeley\n",
    "#### Based on MATLAB code by [Skip Garibaldi](http://www.garibaldibros.com/)\n",
    "\n",
    "This tool appraises whether it is plausible that a given individual won a set of lottery prizes honestly. \n",
    "\n",
    "The code reads a comma-separated values file (CSV) of wins and odds.\n",
    "\n",
    "The user inputs the number of residents of the state, and a tiny \"threshold\" probability.\n",
    "\n",
    "The code outputs a lower bound on the amount everyone in the state would have had to spend for any of them to have a tiny chance of winning so often, where \"tiny\" is the threshold number chosen by the user.\n",
    "\n",
    "If the required spending amount is, for example, several times the median house price in the state, it may call into question whether the winner won honestly.\n",
    "\n",
    "The current version can analyze data for only one gambler at a time. \n",
    "\n",
    "The code implements the mathematics described in the first link below. The third link is to a public lecture about the method, and results for reported lottery winners in Florida. \n",
    "\n",
    "See:\n",
    "+ Arratia, R., S. Garibaldi, L. Mower, and P.B. Stark, 2015. Some people have all the luck. _Mathematics Magazine_, _88_ 196–211. doi:10.4169/math.mag.88.3.196.c, Reprint: http://www.stat.berkeley.edu/~stark/Preprints/luck15.pdf http://www.jstor.org/stable/10.4169/math.mag.88.3.196\n",
    "+ Arratia, R., S. Garibaldi, L. Mower, and P.B. Stark, 2015. Some people have all the luck &hellip; or do they? _MAA Focus_, August/September, 37–38. http://www.maa.org/sites/default/files/pdf/MAAFocus/Focus_AugustSeptember_2015.pdf\n",
    "+ https://www.youtube.com/watch?v=s8cHHWNblA4\n",
    "+  Lottery odds: To win, you’d have to be a loser. Lawrence Mower, _Palm Beach Post_, 28 March 2014. http://www.mypalmbeachpost.com/news/news/lottery-odds-to-win-youd-have-to-be-a-loser/nfL57\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "1. Compile a CSV file for each gambler. The CSV file should contain three columns:  \"Probability,\" \"Number,\" and \"Cost.\" \n",
    "\n",
    "Each row corresponds to one type of wager. \"Probability\" is the chance of winning that wager; \"Number\" is the number of times the gambler collected on that wager; and \"Cost\" is the cost per ticket or play on that wager. The computations assume that the gambler did not win any dependent bets, for instance, two bets on the same drawing.\n",
    "\n",
    "2. Put the filename of your CSV file in the box below, along with the values of POPULATION and THRESHOLD.\n",
    "\n",
    "3. On the toolbar of this browser window (under the jupyter logo), click \"Cell\" --> \"Run All\". Wait a bit for your results to appear at the bottom of this page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "# Put the name of your CSV file here:\n",
    "# CSV_FILENAME = 'FILL_ME_IN.csv'\n",
    "# CSV_FILENAME = 'manning-edit.csv'\n",
    "CSV_FILENAME = 'pandya.csv'\n",
    "\n",
    "# set the population size and overall cutoff probability\n",
    "POPULATION = 10**7   # population of North Carolina\n",
    "THRESHOLD =  10**(-7) # one in ten million threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import betainc\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def binTail(p, n, t): # upper tail probability for a vector of Binomial(n,p) random variables\n",
    "    return betainc(n, t - n + 1, p)\n",
    "\n",
    "def binTailln(p, n, t): # logarithm of the upper tail probability for a vector of Binomial(n,p) random variables\n",
    "    return np.log(binTail(p, n, t))\n",
    "\n",
    "def constraintFn(p, n): # constraint function: probability of vector of wins must be at least CUT\n",
    "    return lambda x: np.sum(binTailln(p, n, x)) - np.log(CUT)\n",
    "\n",
    "def objectiveFn(c):  # construct function that gives cost of vector x of bets, for cost-per-bet vector c\n",
    "    return lambda x: np.dot(x, c)\n",
    "\n",
    "def solve(x0, upperBoundVec, p, n, c, eps, debugMode, maxiter, method='SLSQP'):  \n",
    "    # invoke the constrained optimizer\n",
    "    # \n",
    "    #    x0:     starting guess\n",
    "    #    p:      vector of game probabilities\n",
    "    #    n:      vector of number of wins of each game\n",
    "    #    c:      vector of game costs\n",
    "    #    eps:    stepsize for Hessian approximation\n",
    "    #    debugMode: True for verbose output\n",
    "    #    maxiter: maximum iterations in optimizer\n",
    "    #    method: underlying minimization algorithm\n",
    "    #       \n",
    "    cons = ({'type': 'ineq', 'fun': constraintFn(p, n)})   # overall probability constraint\n",
    "    bnds = tuple((n[i], upperBoundVec[i]) for i in range(len(n)))  # must bet at least n times to win n times\n",
    "    return minimize(objectiveFn(c), x0, method=method, jac=(lambda x: c),\n",
    "                    constraints=cons, bounds=bnds,\n",
    "                    options={'disp': debugMode, 'maxiter': maxiter, 'eps': eps})\n",
    "\n",
    "def readCsv(filename):  # read the csv file of data for a player\n",
    "    with open(CSV_FILENAME, 'r') as f:\n",
    "        firstLine = f.readline()\n",
    "        if firstLine.strip() != \"Probability,Number,Cost\":\n",
    "            raise Exception('Data column headings should be \"Probability, Number, Cost\"')\n",
    "    values = np.loadtxt(filename, dtype=np.float_, delimiter=',', skiprows=1)  # skip the header\n",
    "    values = np.atleast_2d(values)\n",
    "    pValues = values[:,0]\n",
    "    nValues = values[:,1]\n",
    "    cValues = values[:,2]\n",
    "    return (pValues, nValues, cValues)\n",
    "\n",
    "def solveProblem(tries=5, debugMode=False, epsilon = 1e-7, epsFac=8, maxiter=10**4):\n",
    "    # Try up to epsFac values of the Hessian step size, related by powers of 10 (Hessian approximation step sizes)\n",
    "    optimalValues = []     # candidate optima\n",
    "    optimalProbs = []      # probabilities associated with those optima\n",
    "    optimalSolutions = []  # detailed optimization output for candidate optima\n",
    "    if debugMode:\n",
    "        print(\"n: {} \\np: {}\".format(n,p))\n",
    "    for meth in methods:   # try different optimization methods\n",
    "        for epsIndex in range(epsFac):  # try different step sizes in the Hessian\n",
    "            x0 = np.array(that/divisor) # starting guess\n",
    "            for i in range(tries):\n",
    "                while (np.sum(np.log(binTail(p, n, x0))) - np.log(CUT)) < 0:  # ensure x0 is a feasible point\n",
    "                    x0 = np.add(x0,np.ones_like(x0))  # increment every element of x\n",
    "                if (debugMode):\n",
    "                    print(\"method: {} try: {} \\nx0: {} \\nprobability {}:\".format(meth,i,x0,\\\n",
    "                                np.prod(binTail(p, n, x0))))\n",
    "                optimOutput = solve(x0, that, p, n, c, epsilon*10**epsIndex, debugMode, maxiter, method=meth)\n",
    "                if optimOutput['success']:\n",
    "                    optimalValues.append(optimOutput['fun'])\n",
    "                    attainedProb = np.prod(binTail(p, n, optimOutput['x']))\n",
    "                    optimalProbs.append(attainedProb)\n",
    "                    optimalSolutions.append(optimOutput)\n",
    "                    if debugMode:\n",
    "                        print(optimOutput)\n",
    "                        print(\"attained probability: {}\".format(attainedProb))\n",
    "                x0 = [np.random.randint(low=n[i], high=that[i]) for i in range(len(n))] # update x0 randomly\n",
    "    if len(optimalValues) == 0:\n",
    "        raise Exception('No candidate optimal solution found.')\n",
    "    bestValue = np.min(optimalValues)\n",
    "    largestProb = np.max(tuple(optimalProbs))\n",
    "    if debugMode:\n",
    "        print(\"\\nFound {} candidate minima: {}\".format(len(optimalValues), optimalValues))\n",
    "        print(\"Best value: {}\".format(bestValue))\n",
    "    print(\"Everyone in the population of {} people would have to spend at least ${:,} to have probability {} that at least one would win these bets so often.\"\n",
    "          .format(POPULATION, np.int(bestValue), THRESHOLD))\n",
    "    return optimalValues, optimalProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(p, n, c) = readCsv(CSV_FILENAME)  # read the data for the player\n",
    "that = n/p  # expected number of wagers on each bet required to win that bet n times\n",
    "\n",
    "debugMode = False  # verbose output if True; set to False for less output\n",
    "\n",
    "np.random.RandomState(seed=1234567890) # setting seed explicitly, for reprodudibility\n",
    "\n",
    "if debugMode:\n",
    "    print (\"initial t_hat: {} \\ninitialprobability: {}\".format(that,np.prod(binTail(p, n, that))))\n",
    "\n",
    "CUT = THRESHOLD / POPULATION # Bonferroni cutoff probability\n",
    "\n",
    "# 'that' will be used as an upper bound; ensure that it's compatible with the probability constraint\n",
    "while np.prod(binTail(p, n, that)) < CUT:\n",
    "    that = 2*that\n",
    "    \n",
    "divisor = 5 # initial value for optimizer is expected number divided by divisor (modified to ensure feasibility)\n",
    "methods = ['SLSQP','COBYLA']  # COBYLA will ignore the individual bounds, but should honor the probability constraint\n",
    "\n",
    "if debugMode:\n",
    "    print (\"adjusted t_hat: {} \\nadjusted probability: {}\".format(that,np.prod(binTail(p, n, that))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone in the population of 10000000 people would have to spend at least $1,080,348 to have probability 1e-07 that at least one would win these bets so often.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.py:378: RuntimeWarning: Method COBYLA does not use gradient information (jac).\n",
      "  RuntimeWarning)\n",
      "//anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.py:397: RuntimeWarning: Method COBYLA cannot handle bounds.\n",
      "  RuntimeWarning)\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:33: OptimizeWarning: Unknown solver options: eps\n"
     ]
    }
   ],
   "source": [
    "optimalValues, optimalProbs = solveProblem(tries = 5, debugMode=debugMode, epsilon = 1e-7, epsFac=8, maxiter=10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9999953345537619e-15, 9.9999956188206947e-15, 9.999994046368117e-15, 9.9999994253008235e-15, 9.9999992777229184e-15, 9.9999936976493045e-15, 9.9999979125815729e-15, 9.9999989229528233e-15, 9.99999607856183e-15, 9.9999948924146931e-15, 9.9999986952259702e-15, 9.99999578082685e-15, 9.999993632752878e-15, 9.9999999069209733e-15, 1.000000005133184e-14, 9.9999991313980447e-15, 9.9999999842248408e-15, 9.9999974316800517e-15, 9.9999996651378322e-15, 9.9999999053038558e-15, 9.9999999688676059e-15, 9.9999998383779537e-15, 9.999999529143802e-15, 9.999999999639896e-15, 9.9999995560141462e-15, 9.999999887132945e-15, 9.9999998111572732e-15, 1.0000000000188282e-14, 9.9999999964263733e-15, 9.9999999463063734e-15, 1.000000000014957e-14, 9.9999999377647532e-15, 9.9999999925341068e-15, 9.9999959766156391e-15, 1.0000000000166514e-14, 1.0000000000110019e-14, 9.9999993961783855e-15, 9.9999991670484045e-15]\n"
     ]
    }
   ],
   "source": [
    "print(optimalProbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
